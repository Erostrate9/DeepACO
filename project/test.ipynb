{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pr439.tsp', 'rd100.tsp', 'rl5934.tsp', 'pcb442.tsp', 'u2319.tsp', 'gil262.tsp', 'pcb3038.tsp', 'lin105.tsp', 'fl417.tsp', 'tsp225.tsp', 'fl1400.tsp', 'nrw1379.tsp', 'd2103.tsp', 'kroA150.tsp', 'pcb1173.tsp', 'd198.tsp', 'fl1577.tsp', 'ch130.tsp', 'kroB100.tsp', 'u1060.tsp', 'berlin52.tsp', 'eil51.tsp', 'rl1304.tsp', 'u2152.tsp', 'u724.tsp', 'kroD100.tsp', 'pr299.tsp', 'rd400.tsp', 'vm1084.tsp', 'rat575.tsp', 'd1655.tsp', 'ch150.tsp', 'd15112.tsp', 'pr107.tsp', 'kroB200.tsp', 'brd14051.tsp', 'a280.tsp', 'd1291.tsp', 'pr264.tsp', 'pr76.tsp', 'd493.tsp', 'pr136.tsp', 'rat195.tsp', 'rl11849.tsp', 'kroA100.tsp', 'kroB150.tsp', 'bier127.tsp', 'kroC100.tsp', 'usa13509.tsp', 'eil76.tsp', 'pr124.tsp', 'rl1323.tsp', 'p654.tsp', 'rl1889.tsp', 'd657.tsp', 'eil101.tsp', 'fnl4461.tsp', 'pr2392.tsp', 'rat783.tsp', 'ts225.tsp', 'u1432.tsp', 'u1817.tsp', 'lin318.tsp', 'd18512.tsp', 'rl5915.tsp', 'st70.tsp', 'rat99.tsp', 'fl3795.tsp', 'u159.tsp', 'kroA200.tsp', 'u574.tsp', 'pr1002.tsp', 'pr152.tsp', 'pr226.tsp', 'vm1748.tsp', 'pr144.tsp', 'kroE100.tsp']\n",
      "Current Working Directory: /Users/erostrate9/Desktop/CSI5137B test/project/code/DeepACO/project\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# os.chdir(\"../\")\n",
    "sys.path.append('../tsp_nls')\n",
    "sys.path.append('../tsp')\n",
    "sys.path.append(\"..\")  # This points to `DeepACO`\n",
    "\n",
    "TSPLIB_DIR = \"../data/tsp/TSPLIB\"\n",
    "tsp_files = [f for f in os.listdir(TSPLIB_DIR) if f.endswith(\".tsp\")]\n",
    "print(tsp_files)\n",
    "\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "import torch\n",
    "from torch.distributions import Categorical, kl\n",
    "# from d2l.torch import Animator\n",
    "\n",
    "from tsp_nls.greedy import test_greedy, GreedyTSP\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Performance of DeepACO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSP500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------ACO Model (LS)-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [15:48<00:00,  7.41s/it]\n",
      "/var/folders/c_/9pzrss116732p7dxch3kn_bc0000gn/T/ipykernel_51980/3555379313.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net_nls.load_state_dict(torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration:  948.8780181407928\n",
      "T=2, average cost is 17.70496368408203.\n",
      "T=12, average cost is 17.522695541381836.\n",
      "-------DeepACO (LS)-------\n",
      "checkpoint: ../pretrained/tsp_nls/tsp500.pt\n",
      "number of instances: 128\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [04:16<00:00,  2.00s/it]\n",
      "/var/folders/c_/9pzrss116732p7dxch3kn_bc0000gn/T/ipykernel_51980/3555379313.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net_nls.load_state_dict(torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  256.3679599761963\n",
      "T=2, average cost is 17.07706069946289.\n",
      "T=12, average cost is 16.96156120300293.\n",
      "-------DeepACO (NLS)-------\n",
      "checkpoint: ../pretrained/tsp_nls/tsp500.pt\n",
      "number of instances: 128\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [20:08<00:00,  9.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  1208.8285551071167\n",
      "T=2, average cost is 16.931360244750977.\n",
      "T=12, average cost is 16.838075637817383.\n",
      "GreedyTSP is using: cpu\n",
      "--------Greedy Algorithm:--------\n",
      "Total duration:  0.5012819766998291\n",
      "Average cost is 20.80839306605617.\n"
     ]
    }
   ],
   "source": [
    "from tsp_nls.utils import load_test_dataset\n",
    "from tsp_nls.test import test\n",
    "import tsp_nls.net as net\n",
    "# import tsp.test_utils as test_aco\n",
    "\n",
    "# Configuration\n",
    "pretrain_n_node = 500\n",
    "n_ants = 50\n",
    "t_aco = [2, 12]\n",
    "k_sparse = 50\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "test_n_node=500\n",
    "\n",
    "model_file = f'../pretrained/tsp_nls/tsp{pretrain_n_node}.pt'\n",
    "\n",
    "test_list = load_test_dataset(test_n_node, k_sparse, device, start_node = 0)\n",
    "res_avg_cost = {}\n",
    "\n",
    "# # Genetic Algorithm\n",
    "# print('-------Genetic Algorithm-------')\n",
    "# import tsp.genetic as genetic\n",
    "\n",
    "# pop_size = 500\n",
    "# crossover_rate = 0.85\n",
    "# mutation_rate=0.15\n",
    "# elitism_count=2\n",
    "# tournament_size=5\n",
    "# # t_ga=[500, 1000] # best performance\n",
    "# t_ga=[100] # limited runtime\n",
    "\n",
    "# ga_res, avg_ga_best, duration_ga = genetic.test_genetic(\n",
    "#     test_list, \n",
    "#     pop_size=pop_size, \n",
    "#     crossover_rate=crossover_rate, \n",
    "#     mutation_rate=mutation_rate, \n",
    "#     elitism_count=elitism_count, \n",
    "#     tournament_size=tournament_size, \n",
    "#     t_ga=t_ga, \n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "# print('Total duration: ', duration_ga)\n",
    "# for i, t in enumerate(t_ga):\n",
    "#     print(f\"T={t}, average cost is {avg_ga_best[i]}.\")\n",
    "#     res_avg_cost[f'Genetic(T={t})'] = float(avg_ga_best[i])\n",
    "\n",
    "# Testing ACO (LS) Model\n",
    "# avg_aco_best, duration = test_aco.test(tsplib_test_list, None, n_ants, t_aco, k_sparse)\n",
    "print('-------ACO Model (LS)-------')\n",
    "avg_aco_best, duration = test(test_list, None, n_ants, t_aco, k_sparse, local_search='2opt')\n",
    "print('Total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'ACO(LS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(f\"T={t}, average cost is {avg_aco_best[i]}.\")\n",
    "    \n",
    "# Testing Deep ACO (LS) Model \n",
    "print('-------DeepACO (LS)-------')\n",
    "print(\"checkpoint:\", model_file)\n",
    "print(\"number of instances:\", len(test_list))\n",
    "print(\"device:\", 'cpu' if device == 'cpu' else device+\"+cpu\" )\n",
    "\n",
    "net_nls = net.Net().to(device)\n",
    "net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
    "avg_aco_best, duration = test(test_list, net_nls, n_ants, t_aco, k_sparse, local_search='2opt')\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'DeepACO(LS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(\"T={}, average cost is {}.\".format(t, avg_aco_best[i]))\n",
    "\n",
    "# Testing Deep ACO Model (NLS)\n",
    "print('-------DeepACO (NLS)-------')\n",
    "print(\"checkpoint:\", model_file)\n",
    "print(\"number of instances:\", len(test_list))\n",
    "print(\"device:\", 'cpu' if device == 'cpu' else device+\"+cpu\" )\n",
    "\n",
    "net_nls = net.Net().to(device)\n",
    "net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
    "avg_aco_best, duration = test(test_list, net_nls, n_ants, t_aco, k_sparse, local_search='nls')\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'DeepACO(NLS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(\"T={}, average cost is {}.\".format(t, avg_aco_best[i]))\n",
    "\n",
    "# Greedy\n",
    "greedy_tsp = GreedyTSP(device=device)\n",
    "avg_greedy_cost, greedy_duration = test_greedy(test_list, greedy_tsp, show_progress=False)\n",
    "print('--------Greedy Algorithm:--------')\n",
    "print('Total duration: ', greedy_duration)\n",
    "print(f\"Average cost is {avg_greedy_cost}.\")\n",
    "res_avg_cost[f'Greedy'] = float(avg_greedy_cost)\n",
    "\n",
    "\n",
    "import csv\n",
    "RES_DIR = 'results/'\n",
    "f_out = f'cost_tsp{test_n_node}.csv'\n",
    "test_set = f'TSP{test_n_node}'\n",
    "\n",
    "with open(RES_DIR + f_out, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow(['method', 'test_set', 'average_cost'])\n",
    "    # Write each key-value pair as a row\n",
    "    for method, avg_cost in res_avg_cost.items():\n",
    "        writer.writerow([method, test_set, avg_cost])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erostrate9/Desktop/CSI5137B test/project/code/DeepACO/project/../tsp_nls/utils.py:94: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_tensor = torch.load(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------ACO Model (LS)-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [14:08<00:00,  6.63s/it]\n",
      "/var/folders/c_/9pzrss116732p7dxch3kn_bc0000gn/T/ipykernel_72612/496587869.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net_nls.load_state_dict(torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration:  848.2977397441864\n",
      "T=2, average cost is 17.7020206451416.\n",
      "T=12, average cost is 17.523035049438477.\n",
      "-------DeepACO (LS)-------\n",
      "checkpoint: ../pretrained/tsp_nls/tsp500-best.pt\n",
      "number of instances: 128\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [03:54<00:00,  1.83s/it]\n",
      "/var/folders/c_/9pzrss116732p7dxch3kn_bc0000gn/T/ipykernel_72612/496587869.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net_nls.load_state_dict(torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  234.34918999671936\n",
      "T=2, average cost is 17.16456413269043.\n",
      "T=12, average cost is 17.00470733642578.\n",
      "-------DeepACO (NLS)-------\n",
      "checkpoint: ../pretrained/tsp_nls/tsp500-best.pt\n",
      "number of instances: 128\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [17:59<00:00,  8.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  1079.3477549552917\n",
      "T=2, average cost is 17.051776885986328.\n",
      "T=12, average cost is 16.91356658935547.\n",
      "GreedyTSP is using: cpu\n",
      "--------Greedy Algorithm:--------\n",
      "Total duration:  0.5416841506958008\n",
      "Average cost is 20.80839306605617.\n"
     ]
    }
   ],
   "source": [
    "from tsp_nls.utils import load_test_dataset\n",
    "from tsp_nls.test import test\n",
    "import tsp_nls.net as net\n",
    "# import tsp.test_utils as test_aco\n",
    "\n",
    "# Configuration\n",
    "pretrain_n_node = 500\n",
    "n_ants = 50\n",
    "t_aco = [2, 12]\n",
    "k_sparse = 50\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "test_n_node=500\n",
    "\n",
    "model_file = f'../pretrained/tsp_nls/tsp{pretrain_n_node}-best.pt'\n",
    "\n",
    "test_list = load_test_dataset(test_n_node, k_sparse, device, start_node = 0)\n",
    "res_avg_cost = {}\n",
    "\n",
    "# # Genetic Algorithm\n",
    "# print('-------Genetic Algorithm-------')\n",
    "# import tsp.genetic as genetic\n",
    "\n",
    "# pop_size = 500\n",
    "# crossover_rate = 0.85\n",
    "# mutation_rate=0.15\n",
    "# elitism_count=2\n",
    "# tournament_size=5\n",
    "# # t_ga=[500, 1000] # best performance\n",
    "# t_ga=[100] # limited runtime\n",
    "\n",
    "# ga_res, avg_ga_best, duration_ga = genetic.test_genetic(\n",
    "#     test_list, \n",
    "#     pop_size=pop_size, \n",
    "#     crossover_rate=crossover_rate, \n",
    "#     mutation_rate=mutation_rate, \n",
    "#     elitism_count=elitism_count, \n",
    "#     tournament_size=tournament_size, \n",
    "#     t_ga=t_ga, \n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "# print('Total duration: ', duration_ga)\n",
    "# for i, t in enumerate(t_ga):\n",
    "#     print(f\"T={t}, average cost is {avg_ga_best[i]}.\")\n",
    "#     res_avg_cost[f'Genetic(T={t})'] = float(avg_ga_best[i])\n",
    "\n",
    "# Testing ACO (LS) Model\n",
    "# avg_aco_best, duration = test_aco.test(tsplib_test_list, None, n_ants, t_aco, k_sparse)\n",
    "# print('-------ACO Model (LS)-------')\n",
    "# avg_aco_best, duration = test(test_list, None, n_ants, t_aco, k_sparse, local_search='2opt')\n",
    "# print('Total duration: ', duration)\n",
    "# for i, t in enumerate(t_aco):\n",
    "#     res_avg_cost[f'ACO(LS)(T={t})'] = float(avg_aco_best[i])\n",
    "#     print(f\"T={t}, average cost is {avg_aco_best[i]}.\")\n",
    "    \n",
    "# Testing Deep ACO (LS) Model \n",
    "print('-------DeepACO (LS)-------')\n",
    "print(\"checkpoint:\", model_file)\n",
    "print(\"number of instances:\", len(test_list))\n",
    "print(\"device:\", 'cpu' if device == 'cpu' else device+\"+cpu\" )\n",
    "\n",
    "net_nls = net.Net().to(device)\n",
    "net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
    "avg_aco_best, duration = test(test_list, net_nls, n_ants, t_aco, k_sparse, local_search='2opt')\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'DeepACO(LS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(\"T={}, average cost is {}.\".format(t, avg_aco_best[i]))\n",
    "\n",
    "# Testing Deep ACO Model (NLS)\n",
    "print('-------DeepACO (NLS)-------')\n",
    "print(\"checkpoint:\", model_file)\n",
    "print(\"number of instances:\", len(test_list))\n",
    "print(\"device:\", 'cpu' if device == 'cpu' else device+\"+cpu\" )\n",
    "\n",
    "net_nls = net.Net().to(device)\n",
    "net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
    "avg_aco_best, duration = test(test_list, net_nls, n_ants, t_aco, k_sparse, local_search='nls')\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'DeepACO(NLS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(\"T={}, average cost is {}.\".format(t, avg_aco_best[i]))\n",
    "\n",
    "# Greedy\n",
    "greedy_tsp = GreedyTSP(device=device)\n",
    "avg_greedy_cost, greedy_duration = test_greedy(test_list, greedy_tsp, show_progress=False)\n",
    "print('--------Greedy Algorithm:--------')\n",
    "print('Total duration: ', greedy_duration)\n",
    "print(f\"Average cost is {avg_greedy_cost}.\")\n",
    "res_avg_cost[f'Greedy'] = float(avg_greedy_cost)\n",
    "\n",
    "\n",
    "import csv\n",
    "RES_DIR = 'results/'\n",
    "f_out = f'cost_tsp{test_n_node}_reproduced.csv'\n",
    "test_set = f'TSP{test_n_node}'\n",
    "\n",
    "with open(RES_DIR + f_out, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow(['method', 'test_set', 'average_cost'])\n",
    "    # Write each key-value pair as a row\n",
    "    for method, avg_cost in res_avg_cost.items():\n",
    "        writer.writerow([method, test_set, avg_cost])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSP1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------ACO Model (LS)-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [31:57<00:00, 14.98s/it]\n",
      "/var/folders/c_/9pzrss116732p7dxch3kn_bc0000gn/T/ipykernel_51980/1465468906.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net_nls.load_state_dict(torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration:  1917.347046136856\n",
      "T=2, average cost is 25.049863815307617.\n",
      "-------DeepACO (LS)-------\n",
      "checkpoint: ../pretrained/tsp_nls/tsp1000.pt\n",
      "number of instances: 128\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [06:35<00:00,  3.09s/it]\n",
      "/var/folders/c_/9pzrss116732p7dxch3kn_bc0000gn/T/ipykernel_51980/1465468906.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net_nls.load_state_dict(torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  395.95121693611145\n",
      "T=2, average cost is 24.173004150390625.\n",
      "-------DeepACO (NLS)-------\n",
      "checkpoint: ../pretrained/tsp_nls/tsp1000.pt\n",
      "number of instances: 128\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [16:33<00:00,  7.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  993.9642057418823\n",
      "T=2, average cost is 24.05609703063965.\n",
      "GreedyTSP is using: cpu\n",
      "--------Greedy Algorithm:--------\n",
      "Total duration:  1.131572961807251\n",
      "Average cost is 28.902860519890396.\n"
     ]
    }
   ],
   "source": [
    "from tsp_nls.utils import load_test_dataset\n",
    "from tsp_nls.test import test\n",
    "import tsp_nls.net as net\n",
    "# import tsp.test_utils as test_aco\n",
    "\n",
    "# Configuration\n",
    "pretrain_n_node = 1000\n",
    "n_ants = 50\n",
    "t_aco = [2]\n",
    "k_sparse = 50\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "test_n_node=1000\n",
    "\n",
    "model_file = f'../pretrained/tsp_nls/tsp{pretrain_n_node}.pt'\n",
    "\n",
    "test_list = load_test_dataset(test_n_node, k_sparse, device, start_node = 0)\n",
    "res_avg_cost = {}\n",
    "\n",
    "# # Genetic Algorithm\n",
    "# print('-------Genetic Algorithm-------')\n",
    "# import tsp.genetic as genetic\n",
    "\n",
    "# pop_size = 500\n",
    "# crossover_rate = 0.85\n",
    "# mutation_rate=0.15\n",
    "# elitism_count=2\n",
    "# tournament_size=5\n",
    "# # t_ga=[500, 1000] # best performance\n",
    "# t_ga=[100] # limited runtime\n",
    "\n",
    "# ga_res, avg_ga_best, duration_ga = genetic.test_genetic(\n",
    "#     test_list, \n",
    "#     pop_size=pop_size, \n",
    "#     crossover_rate=crossover_rate, \n",
    "#     mutation_rate=mutation_rate, \n",
    "#     elitism_count=elitism_count, \n",
    "#     tournament_size=tournament_size, \n",
    "#     t_ga=t_ga, \n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "# print('Total duration: ', duration_ga)\n",
    "# for i, t in enumerate(t_ga):\n",
    "#     print(f\"T={t}, average cost is {avg_ga_best[i]}.\")\n",
    "#     res_avg_cost[f'Genetic(T={t})'] = float(avg_ga_best[i])\n",
    "\n",
    "# Testing ACO (LS) Model\n",
    "# avg_aco_best, duration = test_aco.test(tsplib_test_list, None, n_ants, t_aco, k_sparse)\n",
    "# print('-------ACO Model (LS)-------')\n",
    "# avg_aco_best, duration = test(test_list, None, n_ants, t_aco, k_sparse, local_search='2opt')\n",
    "# print('Total duration: ', duration)\n",
    "# for i, t in enumerate(t_aco):\n",
    "#     res_avg_cost[f'ACO(LS)(T={t})'] = float(avg_aco_best[i])\n",
    "#     print(f\"T={t}, average cost is {avg_aco_best[i]}.\")\n",
    "    \n",
    "# Testing Deep ACO (LS) Model \n",
    "print('-------DeepACO (LS)-------')\n",
    "print(\"checkpoint:\", model_file)\n",
    "print(\"number of instances:\", len(test_list))\n",
    "print(\"device:\", 'cpu' if device == 'cpu' else device+\"+cpu\" )\n",
    "\n",
    "net_nls = net.Net().to(device)\n",
    "net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
    "avg_aco_best, duration = test(test_list, net_nls, n_ants, t_aco, k_sparse, local_search='2opt')\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'DeepACO(LS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(\"T={}, average cost is {}.\".format(t, avg_aco_best[i]))\n",
    "\n",
    "# Testing Deep ACO Model (NLS)\n",
    "print('-------DeepACO (NLS)-------')\n",
    "print(\"checkpoint:\", model_file)\n",
    "print(\"number of instances:\", len(test_list))\n",
    "print(\"device:\", 'cpu' if device == 'cpu' else device+\"+cpu\" )\n",
    "\n",
    "net_nls = net.Net().to(device)\n",
    "net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
    "avg_aco_best, duration = test(test_list, net_nls, n_ants, t_aco, k_sparse, local_search='nls')\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'DeepACO(NLS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(\"T={}, average cost is {}.\".format(t, avg_aco_best[i]))\n",
    "    \n",
    "# Greedy\n",
    "greedy_tsp = GreedyTSP(device=device)\n",
    "avg_greedy_cost, greedy_duration = test_greedy(test_list, greedy_tsp, show_progress=False)\n",
    "print('--------Greedy Algorithm:--------')\n",
    "print('Total duration: ', greedy_duration)\n",
    "print(f\"Average cost is {avg_greedy_cost}.\")\n",
    "res_avg_cost[f'Greedy'] = float(avg_greedy_cost)\n",
    "\n",
    "\n",
    "import csv\n",
    "RES_DIR = 'results/'\n",
    "f_out = f'cost_tsp{test_n_node}.csv'\n",
    "test_set = f'TSP{test_n_node}'\n",
    "\n",
    "with open(RES_DIR + f_out, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow(['method', 'test_set', 'average_cost'])\n",
    "    # Write each key-value pair as a row\n",
    "    for method, avg_cost in res_avg_cost.items():\n",
    "        writer.writerow([method, test_set, avg_cost])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/9pzrss116732p7dxch3kn_bc0000gn/T/ipykernel_72612/2947436511.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net_nls.load_state_dict(torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------DeepACO (LS)-------\n",
      "checkpoint: ../pretrained/tsp_nls/tsp1000-best.pt\n",
      "number of instances: 128\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [29:21<00:00, 13.76s/it]\n",
      "/var/folders/c_/9pzrss116732p7dxch3kn_bc0000gn/T/ipykernel_72612/2947436511.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net_nls.load_state_dict(torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  1761.2105638980865\n",
      "T=2, average cost is 24.186599731445312.\n",
      "T=12, average cost is 23.970861434936523.\n",
      "-------DeepACO (NLS)-------\n",
      "checkpoint: ../pretrained/tsp_nls/tsp1000-best.pt\n",
      "number of instances: 128\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [1:28:14<00:00, 41.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  5294.3274211883545\n",
      "T=2, average cost is 24.059968948364258.\n",
      "T=12, average cost is 23.863157272338867.\n",
      "GreedyTSP is using: cpu\n",
      "--------Greedy Algorithm:--------\n",
      "Total duration:  1.160876989364624\n",
      "Average cost is 28.902860519890396.\n"
     ]
    }
   ],
   "source": [
    "from tsp_nls.utils import load_test_dataset\n",
    "from tsp_nls.test import test\n",
    "import tsp_nls.net as net\n",
    "# import tsp.test_utils as test_aco\n",
    "\n",
    "# Configuration\n",
    "pretrain_n_node = 1000\n",
    "n_ants = 100\n",
    "t_aco = [2, 12]\n",
    "k_sparse = 100\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "test_n_node=1000\n",
    "\n",
    "model_file = f'../pretrained/tsp_nls/tsp{pretrain_n_node}-best.pt'\n",
    "\n",
    "test_list = load_test_dataset(test_n_node, k_sparse, device, start_node = 0)\n",
    "res_avg_cost = {}\n",
    "\n",
    "# # Genetic Algorithm\n",
    "# print('-------Genetic Algorithm-------')\n",
    "# import tsp.genetic as genetic\n",
    "\n",
    "# pop_size = 500\n",
    "# crossover_rate = 0.85\n",
    "# mutation_rate=0.15\n",
    "# elitism_count=2\n",
    "# tournament_size=5\n",
    "# # t_ga=[500, 1000] # best performance\n",
    "# t_ga=[100] # limited runtime\n",
    "\n",
    "# ga_res, avg_ga_best, duration_ga = genetic.test_genetic(\n",
    "#     test_list, \n",
    "#     pop_size=pop_size, \n",
    "#     crossover_rate=crossover_rate, \n",
    "#     mutation_rate=mutation_rate, \n",
    "#     elitism_count=elitism_count, \n",
    "#     tournament_size=tournament_size, \n",
    "#     t_ga=t_ga, \n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "# print('Total duration: ', duration_ga)\n",
    "# for i, t in enumerate(t_ga):\n",
    "#     print(f\"T={t}, average cost is {avg_ga_best[i]}.\")\n",
    "#     res_avg_cost[f'Genetic(T={t})'] = float(avg_ga_best[i])\n",
    "\n",
    "# Testing ACO (LS) Model\n",
    "# avg_aco_best, duration = test_aco.test(tsplib_test_list, None, n_ants, t_aco, k_sparse)\n",
    "# print('-------ACO Model (LS)-------')\n",
    "# avg_aco_best, duration = test(test_list, None, n_ants, t_aco, k_sparse, local_search='2opt')\n",
    "# print('Total duration: ', duration)\n",
    "# for i, t in enumerate(t_aco):\n",
    "#     res_avg_cost[f'ACO(LS)(T={t})'] = float(avg_aco_best[i])\n",
    "#     print(f\"T={t}, average cost is {avg_aco_best[i]}.\")\n",
    "    \n",
    "# Testing Deep ACO (LS) Model \n",
    "print('-------DeepACO (LS)-------')\n",
    "print(\"checkpoint:\", model_file)\n",
    "print(\"number of instances:\", len(test_list))\n",
    "print(\"device:\", 'cpu' if device == 'cpu' else device+\"+cpu\" )\n",
    "\n",
    "net_nls = net.Net().to(device)\n",
    "net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
    "avg_aco_best, duration = test(test_list, net_nls, n_ants, t_aco, k_sparse, local_search='2opt')\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'DeepACO(LS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(\"T={}, average cost is {}.\".format(t, avg_aco_best[i]))\n",
    "\n",
    "# Testing Deep ACO Model (NLS)\n",
    "print('-------DeepACO (NLS)-------')\n",
    "print(\"checkpoint:\", model_file)\n",
    "print(\"number of instances:\", len(test_list))\n",
    "print(\"device:\", 'cpu' if device == 'cpu' else device+\"+cpu\" )\n",
    "\n",
    "net_nls = net.Net().to(device)\n",
    "net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
    "avg_aco_best, duration = test(test_list, net_nls, n_ants, t_aco, k_sparse, local_search='nls')\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'DeepACO(NLS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(\"T={}, average cost is {}.\".format(t, avg_aco_best[i]))\n",
    "\n",
    "# Greedy\n",
    "greedy_tsp = GreedyTSP(device=device)\n",
    "avg_greedy_cost, greedy_duration = test_greedy(test_list, greedy_tsp, show_progress=False)\n",
    "print('--------Greedy Algorithm:--------')\n",
    "print('Total duration: ', greedy_duration)\n",
    "print(f\"Average cost is {avg_greedy_cost}.\")\n",
    "res_avg_cost[f'Greedy'] = float(avg_greedy_cost)\n",
    "\n",
    "\n",
    "import csv\n",
    "RES_DIR = 'results/'\n",
    "f_out = f'cost_tsp{test_n_node}_reproduced.csv'\n",
    "test_set = f'TSP{test_n_node}'\n",
    "\n",
    "with open(RES_DIR + f_out, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow(['method', 'test_set', 'average_cost'])\n",
    "    # Write each key-value pair as a row\n",
    "    for method, avg_cost in res_avg_cost.items():\n",
    "        writer.writerow([method, test_set, avg_cost])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Generalization performance of DeepACO across TSP scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TSP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erostrate9/Desktop/CSI5137B test/project/code/DeepACO/project/../tsp_nls/utils.py:94: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_tensor = torch.load(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Genetic Algorithm-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Genetic Algorithm...: 100%|██████████| 128/128 [07:55<00:00,  3.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration:  475.86718797683716\n",
      "T=100, average cost is 150.9008331298828.\n",
      "-------ACO Model (LS)-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [06:41<00:00,  3.13s/it]\n",
      "/var/folders/c_/9pzrss116732p7dxch3kn_bc0000gn/T/ipykernel_51980/1757052597.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net_nls.load_state_dict(torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration:  401.16883397102356\n",
      "T=2, average cost is 17.7701416015625.\n",
      "T=10, average cost is 17.6475830078125.\n",
      "-------DeepACO (LS)-------\n",
      "checkpoint: ../pretrained/tsp_nls/tsp100-best.pt\n",
      "number of instances: 128\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:44<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  104.9275450706482\n",
      "T=2, average cost is 17.21586036682129.\n",
      "T=10, average cost is 17.043716430664062.\n",
      "GreedyTSP is using: cpu\n",
      "--------Greedy Algorithm:--------\n",
      "Total duration:  0.4912858009338379\n",
      "Average cost is 20.80839306605617.\n"
     ]
    }
   ],
   "source": [
    "from tsp_nls.utils import load_test_dataset\n",
    "from tsp_nls.test import test\n",
    "import tsp_nls.net as net\n",
    "# import tsp.test_utils as test_aco\n",
    "\n",
    "# Configuration\n",
    "pretrain_n_node = 100\n",
    "n_ants = 20\n",
    "t_aco = [2, 10]\n",
    "k_sparse = 20\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "test_n_node=500\n",
    "\n",
    "model_file = f'../pretrained/tsp_nls/tsp{pretrain_n_node}-best.pt'\n",
    "\n",
    "test_list = load_test_dataset(test_n_node, k_sparse, device, start_node = 0)\n",
    "res_avg_cost = {}\n",
    "\n",
    "# Genetic Algorithm\n",
    "print('-------Genetic Algorithm-------')\n",
    "import tsp.genetic as genetic\n",
    "\n",
    "pop_size = 500\n",
    "crossover_rate = 0.85\n",
    "mutation_rate=0.15\n",
    "elitism_count=2\n",
    "tournament_size=5\n",
    "# t_ga=[500, 1000] # best performance\n",
    "t_ga=[100] # limited runtime\n",
    "\n",
    "ga_res, avg_ga_best, duration_ga = genetic.test_genetic(\n",
    "    test_list, \n",
    "    pop_size=pop_size, \n",
    "    crossover_rate=crossover_rate, \n",
    "    mutation_rate=mutation_rate, \n",
    "    elitism_count=elitism_count, \n",
    "    tournament_size=tournament_size, \n",
    "    t_ga=t_ga, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "print('Total duration: ', duration_ga)\n",
    "for i, t in enumerate(t_ga):\n",
    "    print(f\"T={t}, average cost is {avg_ga_best[i]}.\")\n",
    "    res_avg_cost[f'Genetic(T={t})'] = float(avg_ga_best[i])\n",
    "\n",
    "# Testing ACO (LS) Model\n",
    "# avg_aco_best, duration = test_aco.test(tsplib_test_list, None, n_ants, t_aco, k_sparse)\n",
    "print('-------ACO Model (LS)-------')\n",
    "avg_aco_best, duration = test(test_list, None, n_ants, t_aco, k_sparse, local_search='2opt')\n",
    "print('Total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'ACO(LS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(f\"T={t}, average cost is {avg_aco_best[i]}.\")\n",
    "    \n",
    "# Testing Deep ACO (LS) Model \n",
    "print('-------DeepACO (LS)-------')\n",
    "print(\"checkpoint:\", model_file)\n",
    "print(\"number of instances:\", len(test_list))\n",
    "print(\"device:\", 'cpu' if device == 'cpu' else device+\"+cpu\" )\n",
    "\n",
    "net_nls = net.Net().to(device)\n",
    "net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
    "avg_aco_best, duration = test(test_list, net_nls, n_ants, t_aco, k_sparse, local_search='2opt')\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'DeepACO(LS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(\"T={}, average cost is {}.\".format(t, avg_aco_best[i]))\n",
    "\n",
    "\n",
    "# Greedy\n",
    "greedy_tsp = GreedyTSP(device=device)\n",
    "avg_greedy_cost, greedy_duration = test_greedy(test_list, greedy_tsp, show_progress=False)\n",
    "print('--------Greedy Algorithm:--------')\n",
    "print('Total duration: ', greedy_duration)\n",
    "print(f\"Average cost is {avg_greedy_cost}.\")\n",
    "res_avg_cost[f'Greedy'] = float(avg_greedy_cost)\n",
    "\n",
    "\n",
    "import csv\n",
    "RES_DIR = 'results/'\n",
    "f_out = f'generalization_cost_tsp{test_n_node}.csv'\n",
    "test_set = f'TSP{test_n_node}'\n",
    "\n",
    "with open(RES_DIR + f_out, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow(['method', 'test_set', 'average_cost'])\n",
    "    # Write each key-value pair as a row\n",
    "    for method, avg_cost in res_avg_cost.items():\n",
    "        writer.writerow([method, test_set, avg_cost])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/9pzrss116732p7dxch3kn_bc0000gn/T/ipykernel_51980/209778338.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net_nls.load_state_dict(torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------DeepACO (NLS)-------\n",
      "checkpoint: ../pretrained/tsp_nls/tsp100-best.pt\n",
      "number of instances: 128\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [07:34<00:00,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  454.75535893440247\n",
      "T=2, average cost is 17.12049102783203.\n",
      "T=10, average cost is 16.970735549926758.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tsp_nls.utils import load_test_dataset\n",
    "from tsp_nls.test import test\n",
    "import tsp_nls.net as net\n",
    "# import tsp.test_utils as test_aco\n",
    "\n",
    "# Configuration\n",
    "pretrain_n_node = 100\n",
    "n_ants = 20\n",
    "t_aco = [2, 10]\n",
    "k_sparse = 20\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "test_n_node=500\n",
    "\n",
    "model_file = f'../pretrained/tsp_nls/tsp{pretrain_n_node}-best.pt'\n",
    "\n",
    "test_list = load_test_dataset(test_n_node, k_sparse, device, start_node = 0)\n",
    "res_avg_cost = {}\n",
    "\n",
    "# Testing Deep ACO Model (NLS)\n",
    "print('-------DeepACO (NLS)-------')\n",
    "print(\"checkpoint:\", model_file)\n",
    "print(\"number of instances:\", len(test_list))\n",
    "print(\"device:\", 'cpu' if device == 'cpu' else device+\"+cpu\" )\n",
    "\n",
    "net_nls = net.Net().to(device)\n",
    "net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
    "avg_aco_best, duration = test(test_list, net_nls, n_ants, t_aco, k_sparse, local_search='nls')\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'DeepACO(NLS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(\"T={}, average cost is {}.\".format(t, avg_aco_best[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TSP1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Genetic Algorithm-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Genetic Algorithm...: 100%|██████████| 128/128 [11:07<00:00,  5.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration:  667.4712688922882\n",
      "[tensor([358.375]), tensor([363.750]), tensor([358.387]), tensor([361.575]), tensor([349.389]), tensor([352.195]), tensor([364.221]), tensor([361.568]), tensor([356.839]), tensor([350.290]), tensor([348.650]), tensor([359.300]), tensor([354.123]), tensor([340.603]), tensor([356.796]), tensor([350.264]), tensor([363.149]), tensor([358.517]), tensor([357.980]), tensor([358.687]), tensor([362.939]), tensor([362.833]), tensor([361.490]), tensor([357.987]), tensor([364.790]), tensor([352.824]), tensor([366.269]), tensor([355.948]), tensor([355.555]), tensor([355.396]), tensor([358.204]), tensor([351.430]), tensor([352.927]), tensor([357.475]), tensor([355.605]), tensor([354.217]), tensor([360.268]), tensor([354.864]), tensor([353.113]), tensor([365.204]), tensor([356.351]), tensor([363.800]), tensor([354.963]), tensor([361.426]), tensor([362.298]), tensor([354.078]), tensor([354.292]), tensor([359.647]), tensor([350.498]), tensor([355.461]), tensor([363.924]), tensor([353.412]), tensor([364.176]), tensor([360.580]), tensor([357.183]), tensor([356.715]), tensor([356.758]), tensor([350.743]), tensor([359.038]), tensor([358.676]), tensor([351.652]), tensor([360.434]), tensor([360.403]), tensor([352.802]), tensor([353.417]), tensor([361.142]), tensor([357.299]), tensor([360.635]), tensor([362.471]), tensor([355.798]), tensor([361.152]), tensor([365.389]), tensor([361.194]), tensor([357.250]), tensor([352.791]), tensor([357.919]), tensor([359.802]), tensor([361.103]), tensor([353.697]), tensor([359.250]), tensor([368.394]), tensor([351.549]), tensor([356.684]), tensor([355.327]), tensor([348.335]), tensor([359.398]), tensor([354.863]), tensor([349.655]), tensor([360.246]), tensor([359.730]), tensor([356.865]), tensor([363.725]), tensor([356.257]), tensor([364.375]), tensor([359.940]), tensor([350.662]), tensor([357.682]), tensor([343.118]), tensor([348.070]), tensor([352.752]), tensor([354.183]), tensor([361.297]), tensor([351.973]), tensor([365.657]), tensor([353.903]), tensor([353.199]), tensor([348.388]), tensor([356.549]), tensor([344.802]), tensor([348.205]), tensor([359.477]), tensor([357.530]), tensor([352.591]), tensor([353.288]), tensor([346.355]), tensor([355.760]), tensor([345.962]), tensor([358.814]), tensor([367.081]), tensor([346.317]), tensor([352.429]), tensor([352.547]), tensor([357.289]), tensor([360.108]), tensor([344.784]), tensor([361.648]), tensor([357.483]), tensor([364.975])]\n",
      "T=100, average cost is 356.6706237792969.\n",
      "-------ACO Model (LS)-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [13:44<00:00,  6.44s/it]\n",
      "/var/folders/c_/9pzrss116732p7dxch3kn_bc0000gn/T/ipykernel_51980/646809438.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net_nls.load_state_dict(torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration:  824.4318702220917\n",
      "T=2, average cost is 25.132539749145508.\n",
      "-------DeepACO (LS)-------\n",
      "checkpoint: ../pretrained/tsp_nls/tsp100-best.pt\n",
      "number of instances: 128\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [03:59<00:00,  1.87s/it]\n",
      "/var/folders/c_/9pzrss116732p7dxch3kn_bc0000gn/T/ipykernel_51980/646809438.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net_nls.load_state_dict(torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  239.235506772995\n",
      "T=2, average cost is 24.45579719543457.\n",
      "-------DeepACO (NLS)-------\n",
      "checkpoint: ../pretrained/tsp_nls/tsp100-best.pt\n",
      "number of instances: 128\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [08:57<00:00,  4.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  537.5747299194336\n",
      "T=2, average cost is 24.344730377197266.\n",
      "GreedyTSP is using: cpu\n",
      "--------Greedy Algorithm:--------\n",
      "Total duration:  1.1108489036560059\n",
      "Average cost is 28.902860519890396.\n"
     ]
    }
   ],
   "source": [
    "from tsp_nls.utils import load_test_dataset\n",
    "from tsp_nls.test import test\n",
    "import tsp_nls.net as net\n",
    "# import tsp.test_utils as test_aco\n",
    "\n",
    "# Configuration\n",
    "pretrain_n_node = 100\n",
    "n_ants = 20\n",
    "t_aco = [2]\n",
    "k_sparse = 20\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "test_n_node=1000\n",
    "\n",
    "model_file = f'../pretrained/tsp_nls/tsp{pretrain_n_node}-best.pt'\n",
    "\n",
    "test_list = load_test_dataset(test_n_node, k_sparse, device, start_node = 0)\n",
    "res_avg_cost = {}\n",
    "\n",
    "# Genetic Algorithm\n",
    "print('-------Genetic Algorithm-------')\n",
    "import tsp.genetic as genetic\n",
    "\n",
    "pop_size = 500\n",
    "crossover_rate = 0.85\n",
    "mutation_rate=0.15\n",
    "elitism_count=2\n",
    "tournament_size=5\n",
    "# t_ga=[500, 1000] # best performance\n",
    "t_ga=[100] # limited runtime\n",
    "\n",
    "res, avg_ga_best, duration_ga = genetic.test_genetic(\n",
    "    test_list, \n",
    "    pop_size=pop_size, \n",
    "    crossover_rate=crossover_rate, \n",
    "    mutation_rate=mutation_rate, \n",
    "    elitism_count=elitism_count, \n",
    "    tournament_size=tournament_size, \n",
    "    t_ga=t_ga, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "print('Total duration: ', duration_ga)\n",
    "print(res)\n",
    "for i, t in enumerate(t_ga):\n",
    "    print(f\"T={t}, average cost is {avg_ga_best[i]}.\")\n",
    "    res_avg_cost[f'Genetic(T={t})'] = float(avg_ga_best[i])\n",
    "\n",
    "# Testing ACO (LS) Model\n",
    "# avg_aco_best, duration = test_aco.test(tsplib_test_list, None, n_ants, t_aco, k_sparse)\n",
    "print('-------ACO Model (LS)-------')\n",
    "avg_aco_best, duration = test(test_list, None, n_ants, t_aco, k_sparse, local_search='2opt')\n",
    "print('Total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'ACO(LS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(f\"T={t}, average cost is {avg_aco_best[i]}.\")\n",
    "    \n",
    "# Testing Deep ACO (LS) Model \n",
    "print('-------DeepACO (LS)-------')\n",
    "print(\"checkpoint:\", model_file)\n",
    "print(\"number of instances:\", len(test_list))\n",
    "print(\"device:\", 'cpu' if device == 'cpu' else device+\"+cpu\" )\n",
    "\n",
    "net_nls = net.Net().to(device)\n",
    "net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
    "avg_aco_best, duration = test(test_list, net_nls, n_ants, t_aco, k_sparse, local_search='2opt')\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'DeepACO(LS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(\"T={}, average cost is {}.\".format(t, avg_aco_best[i]))\n",
    "\n",
    "# Testing Deep ACO Model (NLS)\n",
    "print('-------DeepACO (NLS)-------')\n",
    "print(\"checkpoint:\", model_file)\n",
    "print(\"number of instances:\", len(test_list))\n",
    "print(\"device:\", 'cpu' if device == 'cpu' else device+\"+cpu\" )\n",
    "\n",
    "net_nls = net.Net().to(device)\n",
    "net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
    "avg_aco_best, duration = test(test_list, net_nls, n_ants, t_aco, k_sparse, local_search='nls')\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'DeepACO(NLS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(\"T={}, average cost is {}.\".format(t, avg_aco_best[i]))\n",
    "\n",
    "# Greedy\n",
    "greedy_tsp = GreedyTSP(device=device)\n",
    "avg_greedy_cost, greedy_duration = test_greedy(test_list, greedy_tsp, show_progress=False)\n",
    "print('--------Greedy Algorithm:--------')\n",
    "print('Total duration: ', greedy_duration)\n",
    "print(f\"Average cost is {avg_greedy_cost}.\")\n",
    "res_avg_cost[f'Greedy'] = float(avg_greedy_cost)\n",
    "\n",
    "\n",
    "import csv\n",
    "RES_DIR = 'results/'\n",
    "f_out = f'generalization_cost_tsp{test_n_node}.csv'\n",
    "test_set = f'TSP{test_n_node}'\n",
    "\n",
    "with open(RES_DIR + f_out, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow(['method', 'test_set', 'average_cost'])\n",
    "    # Write each key-value pair as a row\n",
    "    for method, avg_cost in res_avg_cost.items():\n",
    "        writer.writerow([method, test_set, avg_cost])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TSPLIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tsplib_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------ACO Model (LS)-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 14.76it/s]\n",
      "/var/folders/c_/9pzrss116732p7dxch3kn_bc0000gn/T/ipykernel_72612/62463609.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net_nls.load_state_dict(torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration:  0.5433483123779297\n",
      "T=2, average cost is 6.89272403717041.\n",
      "T=10, average cost is 6.8211469650268555.\n",
      "-------DeepACO (LS)-------\n",
      "checkpoint: ../pretrained/tsp_nls/tsp100-best.pt\n",
      "number of instances: 8\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 22.40it/s]\n",
      "/var/folders/c_/9pzrss116732p7dxch3kn_bc0000gn/T/ipykernel_72612/62463609.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net_nls.load_state_dict(torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  0.357973575592041\n",
      "T=2, average cost is 6.812536716461182.\n",
      "T=10, average cost is 6.774055480957031.\n",
      "-------DeepACO (NLS)-------\n",
      "checkpoint: ../pretrained/tsp_nls/tsp100-best.pt\n",
      "number of instances: 8\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:02<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  2.4848527908325195\n",
      "T=2, average cost is 6.76121187210083.\n",
      "T=10, average cost is 6.725982666015625.\n",
      "GreedyTSP is using: cpu\n",
      "--------Greedy Algorithm:--------\n",
      "Total duration:  0.008374691009521484\n",
      "Average cost is 8.316447482560761.\n",
      "-------Genetic Algorithm-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Genetic Algorithm...: 100%|██████████| 8/8 [00:22<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration:  22.399849891662598\n",
      "T=100, average cost is 214.61898803710938.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tsp_nls.utils import load_TSPLIB_test_instance\n",
    "from tsp_nls.test import test\n",
    "import tsp_nls.net as net\n",
    "# import tsp.test_utils as test_aco\n",
    "\n",
    "# Configuration\n",
    "pretrain_n_node = 100\n",
    "n_ants = 20\n",
    "t_aco = [2, 10]\n",
    "k_sparse = 20\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "\n",
    "# model_file = f'../pretrained/tsp_nls/tsp{pretrain_n_node}.pt'\n",
    "model_file = f'../pretrained/tsp_nls/tsp{pretrain_n_node}-best.pt'\n",
    "\n",
    "TSPLIB_DIR = '../data/tsp/TSPLIB'\n",
    "file_names=['bier127.tsp', 'ch130.tsp', 'ch150.tsp', 'eil101.tsp', 'kroA100.tsp', 'kroA150.tsp', 'kroB100.tsp', 'kroC100.tsp',\n",
    "            'kroD100.tsp', 'kroE100.tsp', 'lin105.tsp', 'pr107.tsp', 'pr124.tsp', 'rd100.tsp']\n",
    "tsplib_test_list = load_TSPLIB_test_instance(dir=TSPLIB_DIR, file_names=file_names, device=device, start_node=0, k_sparse = k_sparse, normalized=True)\n",
    "res_avg_cost = {}\n",
    "\n",
    "    \n",
    "# Testing ACO (LS) Model\n",
    "# avg_aco_best, duration = test_aco.test(tsplib_test_list, None, n_ants, t_aco, k_sparse)\n",
    "print('-------ACO Model (LS)-------')\n",
    "avg_aco_best, duration = test(tsplib_test_list, None, n_ants, t_aco, k_sparse, local_search='2opt')\n",
    "print('Total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'ACO(LS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(f\"T={t}, average cost is {avg_aco_best[i]}.\")\n",
    "    \n",
    "# Testing Deep ACO (LS) Model \n",
    "print('-------DeepACO (LS)-------')\n",
    "print(\"checkpoint:\", model_file)\n",
    "print(\"number of instances:\", len(tsplib_test_list))\n",
    "print(\"device:\", 'cpu' if device == 'cpu' else device+\"+cpu\" )\n",
    "\n",
    "net_nls = net.Net().to(device)\n",
    "net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
    "avg_aco_best, duration = test(tsplib_test_list, net_nls, n_ants, t_aco, k_sparse, local_search='2opt')\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'DeepACO(LS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(\"T={}, average cost is {}.\".format(t, avg_aco_best[i]))\n",
    "\n",
    "# Testing Deep ACO Model (NLS)\n",
    "print('-------DeepACO (NLS)-------')\n",
    "print(\"checkpoint:\", model_file)\n",
    "print(\"number of instances:\", len(tsplib_test_list))\n",
    "print(\"device:\", 'cpu' if device == 'cpu' else device+\"+cpu\" )\n",
    "\n",
    "net_nls = net.Net().to(device)\n",
    "net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
    "avg_aco_best, duration = test(tsplib_test_list, net_nls, n_ants, t_aco, k_sparse, local_search='nls')\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'DeepACO(NLS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(\"T={}, average cost is {}.\".format(t, avg_aco_best[i]))\n",
    "\n",
    "# Greedy\n",
    "greedy_tsp = GreedyTSP(device=device)\n",
    "avg_greedy_cost, greedy_duration = test_greedy(tsplib_test_list, greedy_tsp, show_progress=False)\n",
    "print('--------Greedy Algorithm:--------')\n",
    "print('Total duration: ', greedy_duration)\n",
    "print(f\"Average cost is {avg_greedy_cost}.\")\n",
    "res_avg_cost[f'Greedy'] = float(avg_greedy_cost)\n",
    "\n",
    "# Genetic Algorithm\n",
    "print('-------Genetic Algorithm-------')\n",
    "import tsp.genetic as genetic\n",
    "\n",
    "pop_size = 500\n",
    "crossover_rate = 0.85\n",
    "mutation_rate=0.15\n",
    "elitism_count=2\n",
    "tournament_size=5\n",
    "# t_ga=[500, 1000] # best performance\n",
    "t_ga=[100] # limited runtime\n",
    "\n",
    "res, avg_ga_best, duration_ga = genetic.test_genetic(\n",
    "    tsplib_test_list, \n",
    "    pop_size=pop_size, \n",
    "    crossover_rate=crossover_rate, \n",
    "    mutation_rate=mutation_rate, \n",
    "    elitism_count=elitism_count, \n",
    "    tournament_size=tournament_size, \n",
    "    t_ga=t_ga, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "print('Total duration: ', duration_ga)\n",
    "for i, t in enumerate(t_ga):\n",
    "    print(f\"T={t}, average cost is {avg_ga_best[i]}.\")\n",
    "    res_avg_cost[f'Genetic(T={t})'] = float(avg_ga_best[i])\n",
    "\n",
    "import csv\n",
    "RES_DIR = 'results/'\n",
    "f_out = 'generalization_cost_tsplib100_14.csv'\n",
    "test_set = 'TSPLIB100'\n",
    "\n",
    "with open(RES_DIR + f_out, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow(['method', 'test_set', 'average_cost'])\n",
    "    # Write each key-value pair as a row\n",
    "    for method, avg_cost in res_avg_cost.items():\n",
    "        writer.writerow([method, test_set, avg_cost])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------ACO Model (LS)-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 14.55it/s]\n",
      "/var/folders/c_/9pzrss116732p7dxch3kn_bc0000gn/T/ipykernel_51980/2635745122.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net_nls.load_state_dict(torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration:  0.27589893341064453\n",
      "T=2, average cost is 8.494874954223633.\n",
      "T=10, average cost is 8.378503799438477.\n",
      "-------DeepACO (LS)-------\n",
      "checkpoint: ../pretrained/tsp_nls/tsp100-best.pt\n",
      "number of instances: 4\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 21.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  0.18797922134399414\n",
      "T=2, average cost is 8.32490062713623.\n",
      "T=10, average cost is 8.238510131835938.\n",
      "-------DeepACO (NLS)-------\n",
      "checkpoint: ../pretrained/tsp_nls/tsp100-best.pt\n",
      "number of instances: 4\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/9pzrss116732p7dxch3kn_bc0000gn/T/ipykernel_51980/2635745122.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duration:  1.2342329025268555\n",
      "T=2, average cost is 8.285407066345215.\n",
      "T=10, average cost is 8.221202850341797.\n",
      "GreedyTSP is using: cpu\n",
      "--------Greedy Algorithm:--------\n",
      "Total duration:  0.00439000129699707\n",
      "Average cost is 10.27803460357245.\n",
      "-------Genetic Algorithm-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Genetic Algorithm...: 100%|██████████| 4/4 [00:11<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration:  11.280088663101196\n",
      "T=100, average cost is 263.1759033203125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tsp_nls.utils import load_TSPLIB_test_instance\n",
    "from tsp_nls.test import test\n",
    "import tsp_nls.net as net\n",
    "# import tsp.test_utils as test_aco\n",
    "\n",
    "# Configuration\n",
    "pretrain_n_node = 100\n",
    "n_ants = 20\n",
    "t_aco = [2, 10]\n",
    "k_sparse = 20\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "\n",
    "# model_file = f'../pretrained/tsp_nls/tsp{pretrain_n_node}.pt'\n",
    "model_file = f'../pretrained/tsp_nls/tsp{pretrain_n_node}-best.pt'\n",
    "\n",
    "TSPLIB_DIR = '../data/tsp/TSPLIB'\n",
    "file_names=['bier127.tsp', 'ch130.tsp', 'ch150.tsp', 'eil101.tsp']\n",
    "tsplib_test_list = load_TSPLIB_test_instance(dir=TSPLIB_DIR, file_names=file_names, device=device, start_node=0, k_sparse = k_sparse, normalized=True)\n",
    "res_avg_cost = {}\n",
    "\n",
    "    \n",
    "# Testing ACO (LS) Model\n",
    "# avg_aco_best, duration = test_aco.test(tsplib_test_list, None, n_ants, t_aco, k_sparse)\n",
    "print('-------ACO Model (LS)-------')\n",
    "avg_aco_best, duration = test(tsplib_test_list, None, n_ants, t_aco, k_sparse, local_search='2opt')\n",
    "print('Total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'ACO(LS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(f\"T={t}, average cost is {avg_aco_best[i]}.\")\n",
    "    \n",
    "# Testing Deep ACO (LS) Model \n",
    "print('-------DeepACO (LS)-------')\n",
    "print(\"checkpoint:\", model_file)\n",
    "print(\"number of instances:\", len(tsplib_test_list))\n",
    "print(\"device:\", 'cpu' if device == 'cpu' else device+\"+cpu\" )\n",
    "\n",
    "net_nls = net.Net().to(device)\n",
    "net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
    "avg_aco_best, duration = test(tsplib_test_list, net_nls, n_ants, t_aco, k_sparse, local_search='2opt')\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'DeepACO(LS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(\"T={}, average cost is {}.\".format(t, avg_aco_best[i]))\n",
    "\n",
    "# Testing Deep ACO Model (NLS)\n",
    "print('-------DeepACO (NLS)-------')\n",
    "print(\"checkpoint:\", model_file)\n",
    "print(\"number of instances:\", len(tsplib_test_list))\n",
    "print(\"device:\", 'cpu' if device == 'cpu' else device+\"+cpu\" )\n",
    "\n",
    "net_nls = net.Net().to(device)\n",
    "net_nls.load_state_dict(torch.load(model_file, map_location=device))\n",
    "avg_aco_best, duration = test(tsplib_test_list, net_nls, n_ants, t_aco, k_sparse, local_search='nls')\n",
    "print('total duration: ', duration)\n",
    "for i, t in enumerate(t_aco):\n",
    "    res_avg_cost[f'DeepACO(NLS)(T={t})'] = float(avg_aco_best[i])\n",
    "    print(\"T={}, average cost is {}.\".format(t, avg_aco_best[i]))\n",
    "\n",
    "# Greedy\n",
    "greedy_tsp = GreedyTSP(device=device)\n",
    "avg_greedy_cost, greedy_duration = test_greedy(tsplib_test_list, greedy_tsp, show_progress=False)\n",
    "print('--------Greedy Algorithm:--------')\n",
    "print('Total duration: ', greedy_duration)\n",
    "print(f\"Average cost is {avg_greedy_cost}.\")\n",
    "res_avg_cost[f'Greedy'] = float(avg_greedy_cost)\n",
    "\n",
    "# Genetic Algorithm\n",
    "print('-------Genetic Algorithm-------')\n",
    "import tsp.genetic as genetic\n",
    "\n",
    "pop_size = 500\n",
    "crossover_rate = 0.85\n",
    "mutation_rate=0.15\n",
    "elitism_count=2\n",
    "tournament_size=5\n",
    "# t_ga=[500, 1000] # best performance\n",
    "t_ga=[100] # limited runtime\n",
    "\n",
    "res, avg_ga_best, duration_ga = genetic.test_genetic(\n",
    "    tsplib_test_list, \n",
    "    pop_size=pop_size, \n",
    "    crossover_rate=crossover_rate, \n",
    "    mutation_rate=mutation_rate, \n",
    "    elitism_count=elitism_count, \n",
    "    tournament_size=tournament_size, \n",
    "    t_ga=t_ga, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "print('Total duration: ', duration_ga)\n",
    "for i, t in enumerate(t_ga):\n",
    "    print(f\"T={t}, average cost is {avg_ga_best[i]}.\")\n",
    "    res_avg_cost[f'Genetic(T={t})'] = float(avg_ga_best[i])\n",
    "\n",
    "import csv\n",
    "RES_DIR = 'results/'\n",
    "f_out = 'generalization_cost_tsplib100.csv'\n",
    "test_set = 'TSPLIB100'\n",
    "\n",
    "with open(RES_DIR + f_out, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow(['method', 'test_set', 'average_cost'])\n",
    "    # Write each key-value pair as a row\n",
    "    for method, avg_cost in res_avg_cost.items():\n",
    "        writer.writerow([method, test_set, avg_cost])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfacs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
